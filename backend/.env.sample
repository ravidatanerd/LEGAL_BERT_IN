# InLegalDesk Backend Configuration
# Copy this file to .env and configure your settings

# ================================
# CORE API CONFIGURATION
# ================================
BACKEND_PORT=8877
DEBUG=false
LOG_LEVEL=INFO

# ================================
# AI MODEL CONFIGURATION
# ================================

# OpenAI API Configuration (Recommended for best results)
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-4-turbo-preview
OPENAI_MAX_TOKENS=4000

# Alternative AI APIs (Optional)
ANTHROPIC_API_KEY=your_anthropic_key_here
GOOGLE_API_KEY=your_google_key_here

# ================================
# VISION-LANGUAGE MODELS (VLM) CONFIGURATION
# ================================

# VLM Processing Order (Choose your preference)
# Available models: openai, donut, pix2struct, tesseract_fallback

# RECOMMENDED: OpenAI first (best quality, requires API key)
VLM_ORDER=openai,donut,pix2struct,tesseract_fallback

# ALTERNATIVE: Use VLM presets for easier configuration
# VLM_PRESET=premium      # OpenAI only (best quality)
# VLM_PRESET=high         # OpenAI + local models (balanced)
# VLM_PRESET=balanced     # Local models first, API fallback
# VLM_PRESET=fast         # OCR first, fast processing
# VLM_PRESET=offline      # No API calls, local only
# VLM_PRESET=basic        # OCR only, fastest

# MANUAL CONFIGURATIONS:
# For API-only (fastest, requires OpenAI key):
# VLM_ORDER=openai,tesseract_fallback

# For offline-only (no API keys needed, slower):
# VLM_ORDER=donut,pix2struct,tesseract_fallback

# For basic OCR only (fastest, lowest quality):
# VLM_ORDER=tesseract_fallback

# VLM Performance Settings
VLM_BATCH_SIZE=4
VLM_TIMEOUT=300
ENABLE_OCR_FALLBACK=true

# ================================
# DOCUMENT PROCESSING
# ================================

# Chunking Configuration
CHUNK_SIZE=1000
CHUNK_OVERLAP=200
MAX_CHUNKS_PER_DOC=100

# File Upload Limits
MAX_FILE_SIZE_MB=50
ALLOWED_EXTENSIONS=pdf,docx,txt,md

# ================================
# RETRIEVAL CONFIGURATION
# ================================

# Vector Database Settings
VECTOR_DB_PATH=./data/vector_db
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2

# Search Settings
MAX_SEARCH_RESULTS=10
SIMILARITY_THRESHOLD=0.7

# BM25 Sparse Retrieval
ENABLE_BM25=true
BM25_K1=1.2
BM25_B=0.75

# ================================
# SECURITY CONFIGURATION
# ================================

# Rate Limiting
RATE_LIMIT_PER_MINUTE=60
RATE_LIMIT_BURST=10

# CORS Settings
CORS_ORIGINS=http://localhost:3000,http://127.0.0.1:3000

# Authentication (Optional)
# JWT_SECRET_KEY=your_jwt_secret_here
# ENABLE_AUTH=false

# ================================
# PERFORMANCE SETTINGS
# ================================

# Threading and Concurrency
MAX_WORKERS=4
ASYNC_TIMEOUT=30

# Caching
ENABLE_CACHE=true
CACHE_TTL=3600

# Memory Management
MAX_MEMORY_MB=4096
ENABLE_MEMORY_MONITORING=true

# ================================
# DEVELOPMENT SETTINGS
# ================================

# Hot Reload (Development only)
RELOAD=false

# Profiling
ENABLE_PROFILING=false
PROFILE_OUTPUT_DIR=./profiles

# Testing
TEST_MODE=false
MOCK_OPENAI=false

# ================================
# LEGAL DOMAIN SPECIFIC
# ================================

# Indian Legal Sources
ENABLE_INDIACODE_INTEGRATION=true
ENABLE_CASE_LAW_SEARCH=true
ENABLE_STATUTE_SEARCH=true

# Legal Citation Extraction
ENABLE_CITATION_EXTRACTION=true
CITATION_CONFIDENCE_THRESHOLD=0.8

# Legal Entity Recognition
ENABLE_LEGAL_NER=true
NER_MODEL_PATH=./models/legal_ner

# ================================
# MONITORING AND LOGGING
# ================================

# Structured Logging
LOG_FORMAT=json
LOG_FILE=./logs/backend.log
LOG_ROTATION=daily

# Metrics
ENABLE_METRICS=true
METRICS_PORT=8878

# Health Checks
HEALTH_CHECK_INTERVAL=60
HEALTH_CHECK_TIMEOUT=10

# ================================
# ADVANCED CONFIGURATION
# ================================

# Model Loading
MODEL_CACHE_DIR=./models
AUTO_DOWNLOAD_MODELS=true
MODEL_DEVICE=auto

# Hybrid AI Configuration
ENABLE_HYBRID_RETRIEVAL=true
DENSE_WEIGHT=0.7
SPARSE_WEIGHT=0.3

# Custom Model Endpoints
# CUSTOM_LLM_ENDPOINT=http://localhost:8080/v1/chat/completions
# CUSTOM_EMBEDDING_ENDPOINT=http://localhost:8080/v1/embeddings